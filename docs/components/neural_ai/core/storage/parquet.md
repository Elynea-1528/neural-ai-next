# ParquetStorageService - Particion√°lt Parquet T√°rol√≥

## üéØ √Åttekint√©s

A `ParquetStorageService` a Neural AI Next rendszer Big Data t√°rol√≥ komponense, amely particion√°lt Parquet form√°tumban t√°rolja a Tick adatokat. A particion√°l√°s d√°tum √©s szimb√≥lum alap√∫, ami lehet≈ëv√© teszi a gyors √©s hat√©kony adatlek√©rdez√©st 25 √©vnyi Tick adatra.

## üì¶ Jellemz≈ëk

### F≈ëbb K√©pess√©gek

- **Particion√°lt T√°rol√°s:** D√°tum √©s szimb√≥lum alap√∫ particion√°l√°s (`/data/tick/EURUSD/tick/year=2023/month=12/day=23/`)
- **Aszinkron M≈±veletek:** Minden t√°rol√°si √©s olvas√°si m≈±velet aszinkron
- **Adatintegrit√°s:** Checksum ellen≈ërz√©s √©s valid√°ci√≥
- **Hat√©kony Lek√©rdez√©s:** Csak a sz√ºks√©ges part√≠ci√≥k bet√∂lt√©se
- **T√∂m√∂r√≠t√©s:** Snappy t√∂m√∂r√≠t√©s a t√°rol√°si hely optimaliz√°l√°s√°hoz
- **T√∂bb szimb√≥lum t√°mogat√°sa:** EURUSD, GBPUSD, USDJPY, USDCHF, XAUUSD

### Technol√≥giai Stack

- **Polars:** Gyors DataFrame feldolgoz√°s
- **FastParquet:** Parquet f√°jlok kezel√©se
- **Loguru:** Struktur√°lt napl√≥z√°s
- **Asyncio:** Aszinkron m≈±veletek

## üèóÔ∏è Architekt√∫ra

### Part√≠ci√≥szerkezet

```
/data/tick/
‚îú‚îÄ‚îÄ EURUSD/
‚îÇ   ‚îú‚îÄ‚îÄ tick/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ year=2023/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ month=12/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ day=01/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.parquet
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ day=02/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ year=2024/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ GBPUSD/
‚îú‚îÄ‚îÄ USDJPY/
‚îú‚îÄ‚îÄ USDCHF/
‚îî‚îÄ‚îÄ XAUUSD/
```

### Adatmodell

```python
class TickData(BaseModel):
    """Tick adat modell."""
    timestamp: datetime
    symbol: str
    bid: float
    ask: float
    volume: Optional[int] = None
    source: str  # 'jforex', 'mt5', 'ibkr'
    
    @property
    def spread(self) -> float:
        """Spread kisz√°m√≠t√°sa."""
        return self.ask - self.bid
    
    @property
    def mid_price(self) -> float:
        """K√∂z√©p√°r kisz√°m√≠t√°sa."""
        return (self.bid + self.ask) / 2
```

## üîß API Referencia

### Oszt√°ly: `ParquetStorageService`

#### Met√≥dusok

##### `__init__()`

Inicializ√°lja a ParquetStorageService-t.

```python
service = ParquetStorageService()
```

##### `store_tick_data(symbol: str, data: pl.DataFrame, date: datetime) -> None`

Tick adatok t√°rol√°sa particion√°lt Parquet form√°tumban.

**Param√©terek:**
- `symbol`: A p√©nzp√°r szimb√≥luma (pl. 'EURUSD')
- `data`: A Tick adatokat tartalmaz√≥ Polars DataFrame
- `date`: A d√°tum, ami alapj√°n a particion√°l√°s t√∂rt√©nik

**Kiv√©telek:**
- `ValueError`: Ha a DataFrame √ºres vagy nem tartalmazza a sz√ºks√©ges oszlopokat

**P√©lda:**
```python
import polars as pl
from datetime import datetime

data = pl.DataFrame({
    'timestamp': [datetime.now()],
    'bid': [1.1000],
    'ask': [1.1002],
    'volume': [1000],
    'source': ['jforex']
})

await service.store_tick_data('EURUSD', data, datetime.now())
```

##### `read_tick_data(symbol: str, start_date: datetime, end_date: datetime) -> pl.DataFrame`

Tick adatok olvas√°sa d√°tumtartom√°nyb√≥l.

**Param√©terek:**
- `symbol`: A p√©nzp√°r szimb√≥luma
- `start_date`: A kezd≈ë d√°tum
- `end_date`: A z√°r√≥ d√°tum

**Visszat√©r√©si √©rt√©k:**
- A Tick adatokat tartalmaz√≥ Polars DataFrame

**P√©lda:**
```python
from datetime import datetime, timedelta

start = datetime(2023, 12, 1)
end = datetime(2023, 12, 31)

data = await service.read_tick_data('EURUSD', start, end)
print(f"Loaded {len(data)} ticks")
```

##### `get_available_dates(symbol: str) -> List[datetime]`

El√©rhet≈ë d√°tumok lek√©rdez√©se egy adott szimb√≥lumhoz.

**Param√©terek:**
- `symbol`: A p√©nzp√°r szimb√≥luma

**Visszat√©r√©si √©rt√©k:**
- Az el√©rhet≈ë d√°tumok list√°ja

**P√©lda:**
```python
dates = await service.get_available_dates('EURUSD')
print(f"Available dates: {len(dates)}")
```

##### `calculate_checksum(symbol: str, date: datetime) -> str`

Adatok checksum sz√°m√≠t√°sa integrit√°s ellen≈ërz√©shez.

**Param√©terek:**
- `symbol`: A p√©nzp√°r szimb√≥luma
- `date`: A d√°tum

**Visszat√©r√©si √©rt√©k:**
- A checksum SHA256 hash

**P√©lda:**
```python
checksum = await service.calculate_checksum('EURUSD', datetime.now())
print(f"Checksum: {checksum}")
```

##### `verify_data_integrity(symbol: str, date: datetime) -> bool`

Adatintegrit√°s ellen≈ërz√©se.

**Param√©terek:**
- `symbol`: A p√©nzp√°r szimb√≥luma
- `date`: A d√°tum

**Visszat√©r√©si √©rt√©k:**
- `True` ha az adatok integrit√°sa megfelel≈ë, egy√©bk√©nt `False`

**P√©lda:**
```python
is_valid = await service.verify_data_integrity('EURUSD', datetime.now())
print(f"Data integrity: {is_valid}")
```

##### `get_storage_stats(symbol: Optional[str] = None) -> Dict[str, Any]`

T√°rol√°si statisztik√°k lek√©rdez√©se.

**Param√©terek:**
- `symbol`: Opcion√°lis szimb√≥lum sz≈±r√©shez

**Visszat√©r√©si √©rt√©k:**
- A statisztik√°kat tartalmaz√≥ dictionary

**P√©lda:**
```python
# √ñsszes statisztika
stats = await service.get_storage_stats()
print(f"Total files: {stats['total_files']}")

# Csak egy szimb√≥lum statisztik√°ja
stats = await service.get_storage_stats('EURUSD')
```

## üîç Haszn√°lati P√©ld√°k

### 1. Alapvet≈ë T√°rol√°s √©s Olvas√°s

```python
import asyncio
from datetime import datetime
import polars as pl
from neural_ai.core.storage.parquet import ParquetStorageService

async def main():
    service = ParquetStorageService()
    
    # Minta adatok l√©trehoz√°sa
    data = pl.DataFrame({
        'timestamp': [datetime(2023, 12, 23, 10, i, 0) for i in range(10)],
        'bid': [1.1000 + i * 0.0001 for i in range(10)],
        'ask': [1.1002 + i * 0.0001 for i in range(10)],
        'volume': [1000 + i * 100 for i in range(10)],
        'source': ['jforex'] * 10
    })
    
    # Adatok t√°rol√°sa
    await service.store_tick_data('EURUSD', data, datetime(2023, 12, 23))
    
    # Adatok olvas√°sa
    result = await service.read_tick_data(
        'EURUSD',
        datetime(2023, 12, 23, 9, 0, 0),
        datetime(2023, 12, 23, 11, 0, 0)
    )
    
    print(f"Loaded {len(result)} ticks")

asyncio.run(main())
```

### 2. Nagy Adathalmaz T√°rol√°sa

```python
async def store_large_dataset():
    service = ParquetStorageService()
    
    # Nagy adathalmaz l√©trehoz√°sa (1M tick)
    timestamps = [datetime.now() + timedelta(seconds=i) for i in range(1_000_000)]
    bids = [1.1000 + i * 0.000001 for i in range(1_000_000)]
    asks = [b + 0.0002 for b in bids]
    
    data = pl.DataFrame({
        'timestamp': timestamps,
        'bid': bids,
        'ask': asks,
        'volume': [1000] * 1_000_000,
        'source': ['mt5'] * 1_000_000
    })
    
    # T√°rol√°s
    await service.store_tick_data('EURUSD', data, datetime.now())
    
    # Statisztik√°k lek√©rdez√©se
    stats = await service.get_storage_stats('EURUSD')
    print(f"Files: {stats['symbols']['EURUSD']['files']}")
    print(f"Size: {stats['symbols']['EURUSD']['size_gb']:.2f} GB")

asyncio.run(store_large_dataset())
```

### 3. Adatintegrit√°s Ellen≈ërz√©se

```python
async def verify_data():
    service = ParquetStorageService()
    symbol = 'EURUSD'
    date = datetime(2023, 12, 23)
    
    # Integrit√°s ellen≈ërz√©se
    is_valid = await service.verify_data_integrity(symbol, date)
    
    if is_valid:
        print("Data integrity: OK")
        
        # Checksum lek√©rdez√©se
        checksum = await service.calculate_checksum(symbol, date)
        print(f"Checksum: {checksum}")
    else:
        print("Data integrity: FAILED")

asyncio.run(verify_data())
```

### 4. T√∂bb Szimb√≥lum Kezel√©se

```python
async def manage_multiple_symbols():
    service = ParquetStorageService()
    symbols = ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'XAUUSD']
    
    for symbol in symbols:
        # Minta adatok l√©trehoz√°sa
        data = pl.DataFrame({
            'timestamp': [datetime.now()],
            'bid': [1.0],  # Placeholder √©rt√©kek
            'ask': [1.0002],
            'volume': [1000],
            'source': ['jforex']
        })
        
        # T√°rol√°s
        await service.store_tick_data(symbol, data, datetime.now())
    
    # √ñsszes statisztika
    stats = await service.get_storage_stats()
    print(f"Total files: {stats['total_files']}")
    print(f"Total size: {stats['total_size_gb']:.2f} GB")
    
    # Szimb√≥lumonk√©nti bont√°s
    for symbol, symbol_stats in stats['symbols'].items():
        print(f"{symbol}: {symbol_stats['files']} files, {symbol_stats['size_gb']:.2f} GB")

asyncio.run(manage_multiple_symbols())
```

## üß™ Tesztel√©s

### Tesztfuttat√°s

```bash
# ParquetStorageService tesztek futtat√°sa
/home/elynea/miniconda3/envs/neural-ai-next/bin/pytest tests/core/storage/test_parquet.py -v

# Teljes coverage
/home/elynea/miniconda3/envs/neural-ai-next/bin/pytest tests/core/storage/test_parquet.py --cov=neural_ai.core.storage.parquet --cov-report=html
```

### F≈ëbb Tesztesetek

1. **Alapvet≈ë t√°rol√°s √©s olvas√°s**
2. **√úres DataFrame kezel√©se**
3. **Hi√°nyz√≥ oszlopok kezel√©se**
4. **Nem l√©tez≈ë adatok olvas√°sa**
5. **El√©rhet≈ë d√°tumok lek√©rdez√©se**
6. **Checksum sz√°m√≠t√°s**
7. **Adatintegrit√°s ellen≈ërz√©s**
8. **T√°rol√°si statisztik√°k**
9. **D√°tum szerinti sz≈±r√©s**
10. **T√∂bb szimb√≥lum kezel√©se**

## üîó Kapcsol√≥d√≥ Dokumentumok

- [Adatt√°rh√°z Specifik√°ci√≥](docs/planning/specs/04_data_warehouse.md)
- [Storage Interface](docs/components/neural_ai/core/storage/interfaces/storage_interface.md)
- [Storage Factory](docs/components/neural_ai/core/storage/implementations/storage_factory.md)
- [Fejleszt√©si √ötmutat√≥](docs/development/unified_development_guide.md)

## üìù Jegyzetek

- A Parquet form√°tum lehet≈ëv√© teszi a hat√©kony t√∂m√∂r√≠t√©st √©s gyors lek√©rdez√©st
- A particion√°l√°s jelent≈ësen jav√≠tja a lek√©rdez√©si teljes√≠tm√©nyt
- Az aszinkron m≈±veletek optimaliz√°lj√°k a nagy adathalmazok kezel√©s√©t
- A checksum ellen≈ërz√©s biztos√≠tja az adatok integrit√°s√°t
- A Polars DataFrame-ek gyorsabbak mint a Pandas DataFrame-ek nagy adathalmazokon