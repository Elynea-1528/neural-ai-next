"""Template for Neural-AI-Next processors.

This file contains a data processing component template that can be used
to create dimension-specific processors.
"""

from typing import Any, Protocol

import pandas as pd

from neural_ai.core.logger import LoggerInterface
from neural_ai.core.logger.implementations import LoggerFactory


class ProcessorInterface(Protocol):
    """Interface for data processors."""

    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """Process input data.

        Args:
            data: Input data to process

        Returns:
            Processed data

        Raises:
            ProcessorError: When processing fails
        """
        ...


class DimensionProcessor:
    """Dimension-specific data processor.

    This component analyzes a market dimension and calculates features.

    Attributes:
        config: Processor configuration
        name: Dimension name
        window: Processing window size
        logger: Logger instance
    """

    def __init__(self, config: dict[str, Any], logger: LoggerInterface | None = None) -> None:
        """Initialize the processor.

        Args:
            config: Processor configuration
            logger: Optional logger instance
        """
        self.config = config
        self.logger = logger or LoggerFactory.get_logger(__name__)

        # Read configuration parameters
        self.name = config.get("name", "dimension_processor")
        self.window = config.get("window", 20)
        self.normalize = config.get("normalize", True)

        # Feature definitions
        self._feature_definitions = self._init_feature_definitions()

        self.logger.info(f"{self.__class__.__name__} initialized with window={self.window}")

    def _init_feature_definitions(self) -> dict[str, dict[str, Any]]:
        """Initialize feature definitions.

        Returns:
            Feature definitions generated by the processor
        """
        return {
            "feature1": {
                "function": self._calculate_feature1,
                "params": {"window": self.window},
                "description": "Description of first feature",
            },
            "feature2": {
                "function": self._calculate_feature2,
                "params": {"window": self.window // 2, "alpha": 0.5},
                "description": "Description of second feature",
            },
        }

    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """Process data and calculate features.

        Args:
            data: OHLCV data in pandas DataFrame

        Returns:
            Original data augmented with calculated features

        Raises:
            ProcessorError: When processing fails
        """
        try:
            self.logger.debug(f"Processing data with shape {data.shape}")

            # Validate data
            self._validate_input(data)

            # Calculate features
            result = data.copy()

            for feature_name, feature_def in self._feature_definitions.items():
                self.logger.debug(f"Calculating feature: {feature_name}")
                result[feature_name] = feature_def["function"](data, **feature_def["params"])

            # Normalize if needed
            if self.normalize:
                result = self._normalize_features(result)

            self.logger.info(
                f"Successfully processed data, added {len(self._feature_definitions)} features"
            )
            return result

        except Exception as e:
            self.logger.error(f"Error processing data: {str(e)}")
            raise ProcessorError(f"Processing failed: {str(e)}") from e

    def _validate_input(self, data: pd.DataFrame) -> None:
        """Validate input data.

        Args:
            data: Data to validate

        Raises:
            ValueError: If data is invalid
        """
        required_columns = ["open", "high", "low", "close", "volume"]
        missing_columns = [col for col in required_columns if col not in data.columns]

        if missing_columns:
            raise ValueError(f"Input data missing required columns: {missing_columns}")

        if len(data) < self.window:
            raise ValueError(
                f"Input data too short (got {len(data)} rows, need at least {self.window})"
            )

    def _normalize_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Normalize features.

        Args:
            data: Data to normalize

        Returns:
            Normalized data
        """
        # Only normalize calculated features, not original OHLCV columns
        feature_columns = list(self._feature_definitions.keys())

        for feature in feature_columns:
            if feature in data.columns:
                # Min-max normalization to 0-1 range
                min_val = data[feature].min()
                max_val = data[feature].max()
                if max_val > min_val:  # Avoid division by zero
                    data[feature] = (data[feature] - min_val) / (max_val - min_val)

        return data

    def _calculate_feature1(self, data: pd.DataFrame, window: int) -> pd.Series:
        """Calculate first feature.

        Args:
            data: Source data
            window: Window size

        Returns:
            Feature values
        """
        # Example: moving average of closing prices
        return data["close"].rolling(window=window).mean()

    def _calculate_feature2(self, data: pd.DataFrame, window: int, alpha: float) -> pd.Series:
        """Calculate second feature.

        Args:
            data: Source data
            window: Window size
            alpha: Additional parameter

        Returns:
            Feature values
        """
        # Example: exponential moving average
        return data["close"].ewm(span=window, alpha=alpha).mean()

    def get_feature_definitions(self) -> dict[str, dict[str, Any]]:
        """Get feature definitions.

        Returns:
            Feature definitions generated by the processor
        """
        return self._feature_definitions


class ProcessorError(Exception):
    """Processor specific exception."""
