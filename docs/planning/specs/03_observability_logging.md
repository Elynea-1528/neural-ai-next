# 03 - Megfigyelhet≈ës√©g √©s Logol√°s (Observability & Logging)

## üéØ C√©l √©s Sz√°nd√©k

Ez a dokumentum defini√°lja a **Neural AI Next** struktur√°lt logol√°si √©s megfigyelhet≈ës√©gi rendszer√©t. A rendszer `structlog`-ot haszn√°l JSON form√°tumban a f√°jlba/adatb√°zisba √≠r√°shoz, √©s sz√≠nes konzol kimenethez a fejleszt√©s sor√°n.

**Filoz√≥fia:** *"Every log tells a story with context"*

---

## üèóÔ∏è Architekt√∫ra √Åttekint√©s

### Logol√°si R√©tegek

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         LOGGING ARCHITECTURE            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   APPLICATION LOGS           ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   - structlog (JSON)         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   - Context: trace_id,       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ     component, symbol        ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                 ‚îÇ                       ‚îÇ
‚îÇ                 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                 ‚îÇ                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   OUTPUT TARGETS             ‚îÇ      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§      ‚îÇ
‚îÇ  ‚îÇ 1. Console (Color)           ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ 2. File (JSON)               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ 3. Database (SQL)            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ 4. Sentry (Errors)           ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Technol√≥giai Stack

### F≈ë F√ºgg≈ës√©gek

```python
# pyproject.toml
dependencies = [
    "structlog>=23.1.0",
    "python-json-logger>=2.0.7",
    "sentry-sdk>=1.35.0",
    "prometheus-client>=0.19.0",
    "opentelemetry-api>=1.21.0",  # J√∂v≈ëbeli tracing
]
```

### Konfigur√°ci√≥

```python
# configs/logger/logging.yaml
version: 1
disable_existing_loggers: false

formatters:
  json:
    class: pythonjsonlogger.jsonlogger.JsonFormatter
    format: "%(asctime)s %(name)s %(levelname)s %(message)s"
  colored:
    class: structlog.stdlib.ProcessorFormatter
    processor: structlog.dev.ConsoleRenderer(colors=True)

handlers:
  console:
    class: logging.StreamHandler
    formatter: colored
    level: INFO
  file:
    class: logging.handlers.RotatingFileHandler
    filename: /var/log/neural_ai/app.log
    formatter: json
    maxBytes: 10485760  # 10MB
    backupCount: 5
    level: DEBUG
  database:
    class: neural_ai.core.logger.handlers.DatabaseHandler
    formatter: json
    level: WARNING

loggers:
  neural_ai:
    level: DEBUG
    handlers: [console, file, database]
    propagate: false

root:
  level: INFO
  handlers: [console]
```

---

## üé® Structlog Konfigur√°ci√≥

### Alap Konfigur√°ci√≥

```python
import structlog
from structlog.types import EventDict, Processor
import logging
import sys
from datetime import datetime

def configure_structlog() -> None:
    """Structlog konfigur√°ci√≥ja."""
    
    # Processzorok l√°ncolata
    processors: List[Processor] = [
        structlog.contextvars.merge_contextvars,
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.processors.TimeStamper(fmt="iso", utc=True),
        add_correlation_id,
        add_component_context,
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
    ]
    
    # Konzol processzor (fejleszt√©shez)
    console_processors = processors + [
        structlog.stdlib.ProcessorFormatter.remove_processors_meta
    ]
    
    # F√°jl processzor (JSON form√°tum)
    file_processors = processors + [
        structlog.processors.JSONRenderer()
    ]
    
    # Structlog konfigur√°ci√≥
    structlog.configure(
        processors=processors,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    
    # Standard logging konfigur√°ci√≥
    logging.basicConfig(
        format="%(message)s",
        stream=sys.stdout,
        level=logging.INFO,
    )
```

### Egy√©ni Processzorok

```python
import uuid
from typing import Dict, Any

def add_correlation_id(logger, method_name, event_dict) -> EventDict:
    """Trace ID hozz√°ad√°sa minden loghoz."""
    # Ha nincs trace_id a contextben, gener√°lunk egyet
    if 'trace_id' not in event_dict:
        event_dict['trace_id'] = str(uuid.uuid4())
    
    return event_dict

def add_component_context(logger, method_name, event_dict) -> EventDict:
    """Komponens kontextus hozz√°ad√°sa."""
    # Komponens nev√©nek kinyer√©se a logger n√©vb≈ël
    logger_name = event_dict.get('logger', '')
    if '.' in logger_name:
        parts = logger_name.split('.')
        if len(parts) >= 2:
            event_dict['component'] = f"{parts[0]}.{parts[1]}"
        else:
            event_dict['component'] = parts[0]
    else:
        event_dict['component'] = logger_name
    
    return event_dict

def add_symbol_context(symbol: str):
    """Szimb√≥lum kontextus hozz√°ad√°sa."""
    structlog.contextvars.clear_contextvars()
    structlog.contextvars.bind_contextvars(symbol=symbol)
```

---

## üìù Log T√≠pusok √©s Form√°tumok

### 1. Market Data Logs

```python
import structlog

logger = structlog.get_logger("neural_ai.core.market_data")

async def process_tick(symbol: str, bid: float, ask: float):
    """Tick adat feldolgoz√°sa."""
    structlog.contextvars.bind_contextvars(symbol=symbol)
    
    logger.info(
        "tick_received",
        bid=bid,
        ask=ask,
        spread=ask - bid,
        source="jforex"
    )
```

**Kimenet (JSON):**
```json
{
  "timestamp": "2023-12-23T21:30:00.123456Z",
  "level": "info",
  "event": "tick_received",
  "symbol": "EURUSD",
  "bid": 1.10456,
  "ask": 1.10458,
  "spread": 0.00002,
  "source": "jforex",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "component": "neural_ai.core.market_data"
}
```

### 2. Trade Execution Logs

```python
logger = structlog.get_logger("neural_ai.core.execution")

async def execute_trade(signal: SignalEvent):
    """Trade v√©grehajt√°sa."""
    structlog.contextvars.bind_contextvars(
        symbol=signal.symbol,
        strategy_id=signal.strategy_id
    )
    
    logger.info(
        "trade_execution_started",
        direction=signal.signal_type,
        confidence=signal.confidence
    )
    
    try:
        # Trade v√©grehajt√°sa
        result = await broker.execute(signal)
        
        logger.info(
            "trade_executed",
            order_id=result.order_id,
            price=result.price,
            volume=result.volume
        )
        
    except Exception as e:
        logger.error(
            "trade_execution_failed",
            error=str(e),
            exc_info=True
        )
        raise
```

**Kimenet (Hiba eset√©n):**
```json
{
  "timestamp": "2023-12-23T21:30:05.789012Z",
  "level": "error",
  "event": "trade_execution_failed",
  "symbol": "EURUSD",
  "strategy_id": "d3_trend_v1",
  "error": "Insufficient funds",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "component": "neural_ai.core.execution",
  "exception": "Traceback (most recent call last)..."
}
```

### 3. Strategy Decision Logs

```python
logger = structlog.get_logger("neural_ai.strategy.engine")

async def generate_signal(market_data: MarketDataEvent):
    """Jelz√©s gener√°l√°sa."""
    structlog.contextvars.bind_contextvars(symbol=market_data.symbol)
    
    # AI model futtat√°sa
    prediction = await model.predict(market_data)
    
    logger.debug(
        "model_prediction",
        prediction=prediction,
        confidence=prediction.confidence,
        model_version="v2.5.1"
    )
    
    if prediction.should_trade:
        logger.info(
            "signal_generated",
            signal_type=prediction.signal_type,
            confidence=prediction.confidence,
            reasoning=prediction.reasoning
        )
```

---

## üóÑÔ∏è Adatb√°zis Logol√°s

### Adatb√°zis Schema

```python
from sqlalchemy import Column, Integer, String, DateTime, JSON, Text
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class LogEntry(Base):
    """Log bejegyz√©s t√°bl√°ja."""
    
    __tablename__ = 'logs'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    timestamp = Column(DateTime, nullable=False, index=True)
    level = Column(String(20), nullable=False, index=True)
    component = Column(String(255), nullable=False, index=True)
    symbol = Column(String(10), index=True)
    trace_id = Column(String(36), index=True)
    event = Column(String(255))
    message = Column(Text)
    data = Column(JSON)  # Egy√©b kontextus adatok
    
    created_at = Column(DateTime, default=datetime.utcnow)
    
    def __repr__(self):
        return f"<LogEntry(level='{self.level}', event='{self.event}')>"
```

### Database Handler

```python
import logging
from sqlalchemy.ext.asyncio import AsyncSession

class DatabaseHandler(logging.Handler):
    """Logol√°s adatb√°zisba."""
    
    def __init__(self, session_factory):
        super().__init__()
        self.session_factory = session_factory
    
    def emit(self, record):
        """Log rekord feldolgoz√°sa."""
        try:
            # JSON adatok kinyer√©se
            data = getattr(record, 'data', {})
            
            log_entry = LogEntry(
                timestamp=datetime.fromtimestamp(record.created),
                level=record.levelname,
                component=getattr(record, 'component', 'unknown'),
                symbol=getattr(record, 'symbol', None),
                trace_id=getattr(record, 'trace_id', None),
                event=getattr(record, 'event', record.getMessage()),
                message=record.getMessage(),
                data=data
            )
            
            # Aszinkron ment√©s
            asyncio.create_task(self._save_log(log_entry))
            
        except Exception as e:
            # Ne dobjunk hib√°t a log handlerben
            print(f"Database log handler error: {e}")
    
    async def _save_log(self, log_entry: LogEntry):
        """Log bejegyz√©s aszinkron ment√©se."""
        async with self.session_factory() as session:
            session.add(log_entry)
            await session.commit()
```

---

## üìä Metrik√°k √©s Monitoring

### Prometheus Metrik√°k

```python
from prometheus_client import Counter, Histogram, Gauge
import time

# Metrik√°k defini√°l√°sa
tick_counter = Counter(
    'neural_ai_ticks_total',
    'Total number of ticks processed',
    ['symbol', 'source']
)

trade_counter = Counter(
    'neural_ai_trades_total',
    'Total number of trades executed',
    ['symbol', 'direction', 'strategy']
)

trade_latency = Histogram(
    'neural_ai_trade_latency_seconds',
    'Trade execution latency',
    ['symbol']
)

active_positions = Gauge(
    'neural_ai_active_positions',
    'Number of active positions',
    ['symbol']
)

# Haszn√°lat
async def process_tick(symbol: str, source: str):
    """Tick feldolgoz√°s metrik√°kkal."""
    tick_counter.labels(symbol=symbol, source=source).inc()
    
    start_time = time.time()
    # Trade v√©grehajt√°s
    await execute_trade(...)
    
    latency = time.time() - start_time
    trade_latency.labels(symbol=symbol).observe(latency)
```

### Grafana Dashboard (Tervez√©s)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         NEURAL AI NEXT - DASHBOARD              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Ticks/sec       ‚îÇ  ‚îÇ Active Positions‚îÇ     ‚îÇ
‚îÇ  ‚îÇ 1,234           ‚îÇ  ‚îÇ 5               ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Trades by Strategy (Last Hour)          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà D3_Trend: 45 trades          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà D2_SR: 28 trades                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚ñà‚ñà‚ñà‚ñà D5_Momentum: 18 trades             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Trade Latency (P99)                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ EURUSD: 125ms                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ XAUUSD: 98ms                            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç Hibakeres√©s √©s Trace-ek

### OpenTelemetry Integr√°ci√≥ (J√∂v≈ëbeli)

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter

def setup_tracing() -> None:
    """Tracing konfigur√°ci√≥."""
    trace.set_tracer_provider(TracerProvider())
    
    # Jaeger exporter (vagy Zipkin, stb.)
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831,
    )
    
    trace.get_tracer_provider().add_span_processor(
        BatchSpanProcessor(jaeger_exporter)
    )

# Haszn√°lat
tracer = trace.get_tracer(__name__)

async def process_market_data(symbol: str):
    """Market data feldolgoz√°s trace-el."""
    with tracer.start_as_current_span("process_market_data") as span:
        span.set_attribute("symbol", symbol)
        
        # Feldolgoz√°s...
        await analyze_data(symbol)
```

---

## üéØ Log Szintek √©s Haszn√°lat

### Log Szintek Strat√©gi√°ja

```python
# DEBUG: R√©szletes fejleszt≈ëi inform√°ci√≥k
logger.debug("detailed_state", internal_state={...})

# INFO: Norm√°l m≈±k√∂d√©s, fontos esem√©nyek
logger.info("trade_executed", order_id="...", price=1.2345)

# WARNING: V√°ratlan, de nem kritikus helyzetek
logger.warning("high_spread", symbol="EURUSD", spread=0.00005)

# ERROR: Hiba t√∂rt√©nt, de az alkalmaz√°s fut tov√°bb
logger.error("api_call_failed", url="...", status_code=500)

# CRITICAL: Kritikus hiba, alkalmaz√°s le√°llhat
logger.critical("database_connection_lost", error="...")
```

### Kontextus Adatok

```python
# Minden loghoz automatikusan hozz√°ad√≥dik:
# - timestamp: ISO 8601 form√°tum
# - trace_id: Egyedi azonos√≠t√≥ a request-hez
# - component: Komponens neve
# - level: Log szint

# K√©zi kontextus hozz√°ad√°sa
structlog.contextvars.bind_contextvars(
    symbol="EURUSD",
    strategy_id="d3_trend_v1",
    user_id="trader_001"
)

logger.info("position_opened", volume=0.1, price=1.1045)
```

---

## üîê Biztons√°g

### √ârz√©keny Adatok Maszkol√°sa

```python
def mask_sensitive_data(logger, method_name, event_dict) -> EventDict:
    """√ârz√©keny adatok maszkol√°sa."""
    sensitive_keys = ['password', 'api_key', 'secret', 'token']
    
    for key in event_dict:
        if any(sensitive in key.lower() for sensitive in sensitive_keys):
            event_dict[key] = '***MASKED***'
    
    return event_dict

# Processzor hozz√°ad√°sa
processors = [
    mask_sensitive_data,
    # ... egy√©b processzorok
]
```

---

## üìã K√∂vetkez≈ë L√©p√©sek

1. **Adatt√°rol√°s:** L√°sd [`04_data_warehouse.md`](04_data_warehouse.md)
2. **Collectorok:** L√°sd [`05_collectors_strategy.md`](05_collectors_strategy.md)

---

## üîó Kapcsol√≥d√≥ Dokumentumok

- [Rendszerarchitekt√∫ra](01_system_architecture.md)
- [Dinamikus Konfigur√°ci√≥](02_dynamic_configuration.md)
- [Fejleszt√©si √ötmutat√≥](docs/development/unified_development_guide.md)